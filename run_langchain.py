import os
import sys
import json
from datetime import datetime
from dotenv import load_dotenv
from typing import Dict, Any, List, Optional

# Rich for UI
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt
from rich.table import Table
from rich import box
from rich.live import Live

# LangChain components
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage, AIMessage
from langchain.tools import tool, StructuredTool
from langchain.agents import AgentExecutor, create_structured_chat_agent
from langchain.memory import ConversationBufferMemory

# Using mock data for testing without API keys
from functionCallListMock import (
    get_time, 
    get_weather, 
    get_coordinates_from_address,
    get_walking_route_planning,
    get_public_transportation_route_planning,
    get_drive_route_planning,
    get_bicycling_route_planning
)

# Initialize Rich console
console = Console()

# Load environment variables
load_dotenv()

# Get API credentials
API_KEY = os.getenv("API_KEY", "")  # LLM API key
MODEL_NAME = os.getenv("MODEL_NAME", "deepseek-ai/DeepSeek-V3")  # Use specified model
USE_MOCK_DATA = True  # é»˜è®¤ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•

# Check if essential API keys are missing
if not API_KEY:
    console.print(Panel.fit(
        "[bold red]Missing API Key[/bold red]\n\n"
        "LLM API key is missing in your .env file.\n\n"
        "Please follow these steps to set up your environment:\n"
        "1. Copy the .env.example file to .env: [cyan]cp .env.example .env[/cyan]\n"
        "2. Edit the .env file and add your API key\n"
        "3. Run the application again\n\n"
        "[bold yellow]Note:[/bold yellow] This application is running in mock mode, which means it can operate without "
        "Weather and Amap API keys by using simulated data.\n\n"
        "[bold red]IMPORTANT:[/bold red] Never commit your API keys to version control or share them publicly.",
        title="âš ï¸ Configuration Warning",
        border_style="red"
    ))
    sys.exit(1)


# Define tool functions using LangChain's tool decorator
@tool
def current_time() -> str:
    """èŽ·å–å½“å‰æ—¶é—´"""
    result = get_time({})
    return result


@tool
def check_weather(location: str) -> str:
    """
    èŽ·å–æŒ‡å®šåœ°ç‚¹çš„å¤©æ°”ä¿¡æ¯
    Args:
        location: éœ€è¦æŸ¥è¯¢å¤©æ°”çš„åœ°ç‚¹ï¼Œå¦‚æ­å·žã€ä¸Šæµ·ã€åŒ—äº¬ç­‰
    """
    result = get_weather({"location": location})
    return result


@tool
def get_coordinates(address: str) -> str:
    """
    å°†åœ°å€è½¬æ¢ä¸ºç»çº¬åº¦åæ ‡
    Args:
        address: è¯¦ç»†åœ°å€ï¼Œå¦‚å¤æ—¦å¤§å­¦æ±Ÿæ¹¾æ ¡åŒºã€åŒ—äº¬å¤©å®‰é—¨ç­‰
    """
    result = get_coordinates_from_address({"address": address})
    return result


@tool
def walking_route(source_address: str, destination_address: str) -> str:
    """
    èŽ·å–æ­¥è¡Œè·¯çº¿è§„åˆ’
    Args:
        source_address: èµ·ç‚¹åœ°å€ï¼Œå¦‚å¤æ—¦å¤§å­¦æ±Ÿæ¹¾æ ¡åŒº
        destination_address: ç»ˆç‚¹åœ°å€ï¼Œå¦‚äº”è§’åœº
    """
    # å…ˆèŽ·å–åæ ‡
    source_data = json.loads(get_coordinates_from_address({"address": source_address}))
    destination_data = json.loads(get_coordinates_from_address({"address": destination_address}))
    
    # æ£€æŸ¥åæ ‡èŽ·å–æ˜¯å¦æˆåŠŸ
    if source_data.get("status") == "1" and source_data.get("geocodes") and \
       destination_data.get("status") == "1" and destination_data.get("geocodes"):
        source = source_data["geocodes"][0]["location"]
        destination = destination_data["geocodes"][0]["location"]
        
        # èŽ·å–è·¯çº¿è§„åˆ’
        result = get_walking_route_planning({
            "source": source,
            "destination": destination
        })
        
        return f"æ­¥è¡Œä»Ž{source_address}åˆ°{destination_address}çš„è·¯çº¿ï¼š\n{result}"
    else:
        return "æ— æ³•èŽ·å–åœ°å€åæ ‡ï¼Œè¯·æ£€æŸ¥åœ°å€æ˜¯å¦æ­£ç¡®"


@tool
def public_transit_route(source_address: str, destination_address: str, city: str = "ä¸Šæµ·") -> str:
    """
    èŽ·å–å…¬å…±äº¤é€šè·¯çº¿è§„åˆ’
    Args:
        source_address: èµ·ç‚¹åœ°å€ï¼Œå¦‚å¤æ—¦å¤§å­¦æ±Ÿæ¹¾æ ¡åŒº
        destination_address: ç»ˆç‚¹åœ°å€ï¼Œå¦‚äº”è§’åœº
        city: åŸŽå¸‚åç§°ï¼Œå¦‚ä¸Šæµ·ã€åŒ—äº¬ç­‰ï¼Œé»˜è®¤ä¸ºä¸Šæµ·
    """
    # å…ˆèŽ·å–åæ ‡
    source_data = json.loads(get_coordinates_from_address({"address": source_address}))
    destination_data = json.loads(get_coordinates_from_address({"address": destination_address}))
    
    # æ£€æŸ¥åæ ‡èŽ·å–æ˜¯å¦æˆåŠŸ
    if source_data.get("status") == "1" and source_data.get("geocodes") and \
       destination_data.get("status") == "1" and destination_data.get("geocodes"):
        source = source_data["geocodes"][0]["location"]
        destination = destination_data["geocodes"][0]["location"]
        
        # èŽ·å–è·¯çº¿è§„åˆ’
        result = get_public_transportation_route_planning({
            "source": source,
            "destination": destination,
            "city": city
        })
        
        return f"å…¬å…±äº¤é€šä»Ž{source_address}åˆ°{destination_address}çš„è·¯çº¿ï¼š\n{result}"
    else:
        return "æ— æ³•èŽ·å–åœ°å€åæ ‡ï¼Œè¯·æ£€æŸ¥åœ°å€æ˜¯å¦æ­£ç¡®"


@tool
def driving_route(source_address: str, destination_address: str) -> str:
    """
    èŽ·å–é©¾è½¦è·¯çº¿è§„åˆ’
    Args:
        source_address: èµ·ç‚¹åœ°å€ï¼Œå¦‚å¤æ—¦å¤§å­¦æ±Ÿæ¹¾æ ¡åŒº
        destination_address: ç»ˆç‚¹åœ°å€ï¼Œå¦‚äº”è§’åœº
    """
    # å…ˆèŽ·å–åæ ‡
    source_data = json.loads(get_coordinates_from_address({"address": source_address}))
    destination_data = json.loads(get_coordinates_from_address({"address": destination_address}))
    
    # æ£€æŸ¥åæ ‡èŽ·å–æ˜¯å¦æˆåŠŸ
    if source_data.get("status") == "1" and source_data.get("geocodes") and \
       destination_data.get("status") == "1" and destination_data.get("geocodes"):
        source = source_data["geocodes"][0]["location"]
        destination = destination_data["geocodes"][0]["location"]
        
        # èŽ·å–è·¯çº¿è§„åˆ’
        result = get_drive_route_planning({
            "source": source,
            "destination": destination
        })
        
        return f"é©¾è½¦ä»Ž{source_address}åˆ°{destination_address}çš„è·¯çº¿ï¼š\n{result}"
    else:
        return "æ— æ³•èŽ·å–åœ°å€åæ ‡ï¼Œè¯·æ£€æŸ¥åœ°å€æ˜¯å¦æ­£ç¡®"


@tool
def bicycle_route(source_address: str, destination_address: str) -> str:
    """
    èŽ·å–éª‘è¡Œè·¯çº¿è§„åˆ’
    Args:
        source_address: èµ·ç‚¹åœ°å€ï¼Œå¦‚å¤æ—¦å¤§å­¦æ±Ÿæ¹¾æ ¡åŒº
        destination_address: ç»ˆç‚¹åœ°å€ï¼Œå¦‚äº”è§’åœº
    """
    # å…ˆèŽ·å–åæ ‡
    source_data = json.loads(get_coordinates_from_address({"address": source_address}))
    destination_data = json.loads(get_coordinates_from_address({"address": destination_address}))
    
    # æ£€æŸ¥åæ ‡èŽ·å–æ˜¯å¦æˆåŠŸ
    if source_data.get("status") == "1" and source_data.get("geocodes") and \
       destination_data.get("status") == "1" and destination_data.get("geocodes"):
        source = source_data["geocodes"][0]["location"]
        destination = destination_data["geocodes"][0]["location"]
        
        # èŽ·å–è·¯çº¿è§„åˆ’
        result = get_bicycling_route_planning({
            "source": source,
            "destination": destination
        })
        
        return f"éª‘è¡Œä»Ž{source_address}åˆ°{destination_address}çš„è·¯çº¿ï¼š\n{result}"
    else:
        return "æ— æ³•èŽ·å–åœ°å€åæ ‡ï¼Œè¯·æ£€æŸ¥åœ°å€æ˜¯å¦æ­£ç¡®"


def display_welcome():
    """Display a welcome message with instructions."""
    console.print(Panel.fit(
        "[bold cyan]Welcome to the AI Assistant (LangChain Edition)[/bold cyan]\n\n"
        "This intelligent assistant can answer questions about:\n"
        "- [green]Current time[/green] (e.g., 'What time is it now?')\n"
        "- [green]Weather information[/green] (e.g., 'How's the weather in Shanghai today?')\n"
        "- [green]Route planning[/green] (e.g., 'How do I get from Fudan University to Wujiaochang?')\n\n"
        f"[bold {'yellow' if USE_MOCK_DATA else 'green'}]{'MOCK MODE ACTIVE' if USE_MOCK_DATA else 'USING REAL APIs'}[/bold {'yellow' if USE_MOCK_DATA else 'green'}]\n\n"
        "Type [bold yellow]exit[/bold yellow], [bold yellow]quit[/bold yellow], or [bold yellow]bye[/bold yellow] to end the conversation.",
        title="ðŸ¤– AI Assistant",
        subtitle="Powered by LangChain & DeepSeek AI",
        border_style="cyan"
    ))


def process_stream_with_ui(content: str):
    """Display streaming content with a nice UI."""
    console.print(Panel(content, title="[bold yellow]A[/bold yellow]: ðŸ¤– Response", border_style="green"))


def main():
    # Display welcome message
    display_welcome()
    
    # Show available capabilities
    capabilities = Table(title="Available Capabilities", box=box.ROUNDED)
    capabilities.add_column("Category", style="cyan")
    capabilities.add_column("Examples", style="green")
    
    capabilities.add_row("Time", "What time is it now?")
    capabilities.add_row("Weather", "How's the weather in Shanghai?\nWhat's the weather forecast for Beijing?")
    capabilities.add_row("Route Planning", "How do I get from Fudan University to Wujiaochang?\nWhat's the best way to travel from Shanghai to Beijing?")
    
    console.print(capabilities)
    
    # Define the tools
    tools = [
        current_time,
        check_weather,
        get_coordinates,
        walking_route,
        public_transit_route,
        driving_route,
        bicycle_route
    ]
    
    # Create system prompt for the agent
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªç”¨äºŽå¯¹è¯åœºæ™¯çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·æ­£ç¡®ã€ç®€æ´ã€æ¯”è¾ƒå£è¯­åŒ–åœ°å›žç­”é—®é¢˜ã€‚
åœ¨å›žç­”ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨æä¾›çš„å·¥å…·æ¥èŽ·å–å®žæ—¶ä¿¡æ¯ï¼Œå¦‚æ—¶é—´ã€å¤©æ°”å’Œè·¯çº¿è§„åˆ’ç­‰ã€‚
ç¡®ä¿ä½ çš„å›žç­”æ¸…æ™°å’Œæœ‰ç”¨ã€‚
"""
    
    # Set up the language model
    model = ChatOpenAI(
        openai_api_key=API_KEY,
        openai_api_base=os.getenv("BASE_URL"),
        model=MODEL_NAME,
        streaming=True,
        temperature=0.7
    )
    
    # Create a memory buffer to maintain conversation context
    memory = ConversationBufferMemory(return_messages=True)
    
    # Create the prompt template
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}")
    ])
    
    # Create the agent
    agent = create_structured_chat_agent(
        llm=model,
        tools=tools,
        prompt=prompt
    )
    
    # Create the agent executor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        memory=memory,
        verbose=False,
        return_intermediate_steps=False
    )
    
    # Conversation loop
    conversation_count = 0
    while True:
        # Add a separator between conversations
        if conversation_count > 0:
            console.rule("[bold blue]New Query[/bold blue]")
        
        # Get user input with a stylish prompt
        user_input = Prompt.ask("\n[bold yellow]Q[/bold yellow]")
        
        # Exit condition
        if user_input.lower() in ["exit", "quit", "bye"]:
            console.print("[bold cyan]Thank you for using the AI Assistant. Goodbye![/bold cyan]")
            break
        
        # Process user input with LangChain agent
        console.print("[bold green]Processing your request...[/bold green]")
        
        try:
            # The streaming callback approach
            result = ""
            
            response_panel = Panel("", title="[bold yellow]A[/bold yellow]: ðŸ¤– Response", border_style="green")
            
            # Live display to show streaming output
            with Live(response_panel, refresh_per_second=10, console=console) as live:
                for chunk in agent_executor.stream({"input": user_input}):
                    if chunk.get("chunks"):
                        for token in chunk["chunks"]:
                            if isinstance(token, str):
                                result += token
                                # Update the panel with each new token
                                response_panel = Panel(
                                    result, 
                                    title="[bold yellow]A[/bold yellow]: ðŸ¤– Response", 
                                    border_style="green"
                                )
                                live.update(response_panel)
        
        except Exception as e:
            console.print(f"[bold red]Error: {str(e)}[/bold red]")
            result = f"I encountered an error while processing your request. Please try again or rephrase your question."
            process_stream_with_ui(result)
        
        conversation_count += 1


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        console.print("[bold red]\nProgram interrupted by user. Exiting...[/bold red]")
    except Exception as e:
        console.print(f"[bold red]Error: {str(e)}[/bold red]") 